## 1.malloc底层实现，vmalloc和kmalloc的区别？

- kmalloc和vmalloc是分配的是内核的内存,malloc分配的是用户的内存；
- kmalloc保证分配的内存在物理上是连续的（虚拟上当然也连续）,vmalloc保证的是在虚拟地址空间上的连续

- kmalloc()分配的内存处于3GB～high_memory之间，而vmalloc()分配的内存在VMALLOC_START～4GB之间，也就是非连续内存区。一般情况下在驱动程序中都是调用kmalloc()来给数据结构分配内存，而vmalloc()用在为活动的交换区分配数据结构，为某些I/O驱动程序分配缓冲区。
- 内存只有在要被DMA访问的时候才需要物理上连续；
- vmalloc 中调用了 kmalloc （GFP—KERNEL），因此也不能应用于原子上下文；



## 2.怎样解决哈希碰撞？

- 开放寻址法
  - 线性探测

- 链表法
- 再哈希法，换一种哈希函数计算直到不冲突
- 建立公共溢出区



## 3.TCP连接突然断电的问题

- 应用层面的心跳机制，俗称心跳包；

  服务器端在一个定时事件中定时向客户端发送一个短小的数据包，然后启动一个线程，在该线程当中不断检测客户端的ACK应答包。如果在定时时间内收到了客户端的ACK应答包，说明客户端与服务器端的TCP连接仍然是可用的。（客户端也可以向服务器发送心跳包）

- TCP协议自带的保活功能，一定时间发送一个包看是否有回应；

  不论是服务器端还是客户端，只要一端开启KeepAlive功能后，就会自动的在规定时间内向对端发送心跳包，而另一端在收到心跳包后就会自动回复，以告诉对端主机我仍然在线。

注意：当服务器突然断电、崩溃从而重启后，如果收到了已关闭的socket发来的消息会翻回RST帧来通知客户端。



## 4.边缘触发为什么高效？使用时要注意什么？

ET是edge trigger，LT是level trigger；

边缘触发是消息到了只会在epoll_wait中通知一次，后续不再通知，因此ET模式在很大程度上减少了通知的次数，因此更加高效；

注意：每个使用ET模式的文件描述符都应该是非阻塞的。 如果描述符是阻塞的，那么读或写操作将会因没有后续事件而一直处于阻塞状态 ( 饥渴状态 )



## 5.topk问题汇总

### 5.1 海量日志数据，提取出某日访问百度次数最多的那个IP

**主要问题**：

IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中处理

**解决方案**：

采用映射的方法，比如模1000，把整个大文件映射为1000个小文件

再找出每个小文中出现频率最大的IP（可以采用hash_map进行频率统计，然后再找出频率最大的几个）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP



### 5.2 统计最热门的10个查询串

搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。
假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

**主要问题**：

内存不能超过1G，一千万条记录，每条记录是255Byte，很显然要占据2.375G内存，这个条件就不满足要求了。

**第一步：Query统计**

**解决方案1**：

用外部排序对所有数据排好序后再遍历所有query，统计每个query的出现次数。O(N+NlgN)=O（NlgN）

**解决方案2**：

题目中说了三百万个，三百万乘以255B是可以容纳在1G中，因此可以就用一个map<query, int>统计每个query的出现次数；

**第二步：找出Top 10**

**解决方案**：

使用大小为10的最小堆。O(K) + O((N-K) x logK)=O(N x logK)



### 5.3 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。

**解决方案**：

(1)分文件（在外存中进行）

顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。

如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。

(2)文件内排序（内存中）
对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。

(3)归并

下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。



### 5.4 在2.5亿个整数中找出不重复的整数（内存不足以容纳这2.5亿个整数）

**解决方案**：

(1)数量计算：

int有4个字节，32位bit，最多可表示  个正整数，即4G个正整数(1G=,1K=) 
用2Bitmap法，每个正整数用两个bit的标志位，00表示没有出现，01表示出现1次，10表示出现多次。 
开辟一个用2Bitmap法标志4G个正整数的桶数组，则总共需要4G*2bit=1G内存。

(2)扫描：

然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。


### 5.5 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url

(1)分文件：

遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,...,a999）中。这样每个小文件的大约为300M。

遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,...,b999）。这样处理后，所有可能相同的url都在对应的小文件（a0vsb0,a1vsb1,...,a999vsb999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。

(2)逐个找重复：

求每对小文件中相同的url： 把其中一个小文件的url存储到hash_set中，然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。



### 5.6 海量数据中位数

只有2G内存的pc机，在一个存有10G个整数的文件，从中找到中位数，写一个算法。

**解决方案**：

极端情况一个数可能出现10G次，因此计数的需要用8B的无符号整数来计数，2G/8B=256M个，因此可以先分为256M个区间，每个区间的计数用一个8B字节统计。

1. 读一遍10G个整数，把整数映射到256M个区段中，用一个64位无符号整数给每个相应区段记数。
2. 从前到后对每一段的计数累加，当累加的和超过5G时停止，找出这个区段（即累加停止时达到的区段，也是中位数所在的区段）的数值范围，设为[a，a+15]，同时记录累加到前一个区段的总数，设为m。然后，释放除这个区段占用的内存。
3. 再读一遍10G个整数，把在[a，a+15]内的每个值计数，即有16个计数。
4. 对新的计数依次累加，每次的和设为n，当m+n的值超过5G时停止，此时的这个计数所对应的数就是中位数。



### 5.7 100000个玩家的战斗力，要排名前500名，而且需要实时更新，怎么处理？

第一、100000名实时遍历系统一定承受不了或者说这样做代价太大，那么可以首先遍历一遍，挑选出战斗力最高的1000名，然后后面只遍历这1000名就可以了，因为前500名大概率都是前一千名产生的，减少系统开销。

第二、为了防止某些玩家充钱了，大幅提升战斗力，那么可以设置一个阈值，如果某个玩家战斗力增加速度超过阈值，那么这个玩家也应该纳入实时排序过程中。

第三、最后100000名玩家的战斗力可以定期在服务器压力不大的时候，比如休服时期或者夜间，做整体排序，以便校验数据的准确性。



### 5.8 一个文件每一行有多个同义词，最后要求分行输出，每一行是合并的同义词集合

(1)建立统计字典，时间O(N)

一个字典：记录每个词出现的行号，最后字典大小为词表大小

(2)获取连通块（这步时间复杂度也是O(N)）

以一个词为起点，通过行号，去扩展连通块，最后能获得一个同义词合集，作为一行输出（被加入的词从字典中删去），然后继续判断下一个词



## 6.Linux中mmap的作用

1. 首先要知道，不管是在用户空间还是在内核空间，软件一律不能去直接访问设备的物理地址；

2. 在内核驱动中如果要访问设备的物理地址，需要利用ioremap将设备的物理地址映射到内核虚拟地址上（动态内存映射区），以后驱动程序访问这个内核虚拟地址就是在间接地访问设备的物理地址（MMU,TLB,TTW） 
3. 如果用户要访问硬件设备，不能直接访问，也不能在用户空间访问，只能通过系统调用(open,close,read,write,ioctl)来访问映射好的内核虚拟

这样就会导致用户如果通过read,write,ioctl来访问硬件设备，它们都要经过两次的数据拷贝，一次是用户空间和内核空间的数据拷贝，另外一次是内核空间和硬件之间的数据拷贝。

而mmap的作用就是将硬件设备的物理地址信息映射到用户的虚拟地址空间即可，一旦完毕，不会在牵扯到内核空间，以后用户直接访问用户的虚拟地址就是在访问设备硬件，由2次的数据拷贝的转换为一次的数据拷贝。



## 7.epoll的优点

1. 支持一个进程打开大数目的socket描述符(FD)；

   传统的Select限制在2048个FD，除非通过改代码重新编译内核解决，或类似Apache利用多进程解决。

   epoll则没有这个限制，它所支持的FD上限是最大可以打开文件的数目, 这个数字一般远大于2048, 1G的内存上是10W左右。

2. IO效率不随FD数目增加而线性下降；

   传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，性能会线性下降;

   epoll不存在这个问题，它只会对"活跃"的socket进行操作(内核实现的原因);

   - 这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的;
   - 只有"活跃"的socket才会主动的去调用 callback函数，其他idle状态socket则不会;（回调函数会把这个socket放到双循环链表中；

3. 使用mmap加速内核与用户空间的消息传递；

   无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的；

4. 因为select/poll每次调用时都要传递你所要监控的所有socket给select/poll系统调用，这意味着需要将用户态的socket列表copy到内核态，如果以万计的句柄会导致每次都要copy几十几百KB的内存到内核态，非常低效;

   epoll_wait却不用传递socket句柄给内核，因为内核已经在epoll_ctl中拿到了要监控的句柄列表;

5. epoll还维护了一个双链表，用户存储发生的事件;
   - 当epoll_wait调用时，仅仅观察这个list链表里有没有数据即eptime项即可;
   - 有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回;
   - 这个准备就绪list链表是怎么维护的呢？
     - 当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外;
     - 还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里;



## 8.TCP中2MSL的作用

**第四次挥手：A发出ACK，用于确认收到B的FIN**

A并不知道B是否接到自己的ACK，A是这么想的：

1）如果B没有收到自己的ACK，会超时重传FIN

那么A再次接到重传的FIN，会再次发送ACK

2）如果B收到自己的ACK，也不会再发任何消息，包括ACK

无论是1还是2，A都需要等待，要取这两种情况等待时间的最大值，**以应对最坏的情况发生**，这个最坏情况是：去向ACK消息最大存活时间（MSL) + 来向FIN消息的最大存活时间(MSL)。这恰恰就是**2MSL( Maximum Segment Life)。**

**为何一定要等2MSL？**
如果不等，释放的端口可能会重连刚断开的服务器端口，这样依然存活在网络里的老的TCP报文可能与新TCP连接报文冲突，造成数据冲突，为避免此种情况，需要耐心等待网络老的TCP连接的活跃报文全部死翘翘，2MSL时间可以满足这个需求（尽管非常保守）



## 9.HTTP1.1和HTTP2.0

- HTTP1.1
  1. 长连接，就是TCP连接Keep-Alive和请求的流水线；（不用流水线的话，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞）
  2. 缓存处理，引入了更多的缓存控制策略；
  3. 带宽优化，允许只请求资源的某个部分；
  4. 错误通知，新增了24个错误状态响应码；
  5. HTTP1.1的请求和响应都要带上Host(Host是要请求的服务器的域名或IP地址)
- HTTP2.0
  1. 全部数据用2进制表示，这就导致HTTP2.0的报文格式像网络报文的那种，先是Length，再是Type。
  2. 多路复用，多个request是可以走同一个TCP连接，是通过request的id字段来进行区分，即单个连接上同时进行多个业务单元数据的传输。
  3. 头部压缩
  4. 服务端推送，在获取html文件时就顺带把css文件也发给你。
  5. 请求优先级。

**HTTP2.0的多路复用解决了HTTP1.X中的长连接复用的什么痛点？**

HTTP1.1尽管减少了TCP连接的消耗，但是本身仍然是串行执行。
HTTP2.0多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；

**HTTP2.0多路复用优势？**

HTTP性能优化的关键并不在于高带宽，而是低延迟。TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 TCP 慢启动。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。
HTTP/2 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升。
（相当于HTTP2可以让某个请求一来就用发育了一段时间的成熟TCP连接）



## 10.mv的话inode会+1么

如果mv命令的目标和源在相同的文件系统：

- 用新的文件名创建对应新的目录项

- 删除旧目录条目对应的旧的文件名

- 不影响inode表（除时间戳）或磁盘上的数据位置：没有数据被移动！

如果目标和源在一个不同的文件系统，mv相当于cp和rm：

CP的命令：

- 分配一个空闲的inode号，在inode表中生成新条目

- 在目录中创建一个目录项，将名称与inode编号关联

- 拷贝数据生成新的文件

RM命令：

- 链接数递减，从而释放的inode号可以被重用

- 把数据块放在空闲列表中

- 删除目录项

- 数据实际上不会马上被删除，但当另一个文件使用数据块时将被覆盖。



## 11.增加服务器的连接池大小可以提高性能么

**结论：不一定会**，过大了反而会由于时间片中切换进程消耗导致速度变慢。且还取决于存储设备、网络等其它因素。

你需要一个小连接池，和一个充满了等待连接的线程的队列。

连接池中的连接数量应该等于你的数据库能够有效同时进行的查询任务数（通常不会高于2*CPU核心数）。

比如一个混合了长事务和短事务的系统，通常是任何连接池都难以进行调优的。最好的办法是创建两个连接池，一个服务于长事务，一个服务于短事务。



## 12.WebSocket与Http优缺点

HTTP协议有一个缺陷：通信只能由客户端发起，做不到服务器主动向客户端推送信息。

WebSocket协议它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。

（注意：Socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们才能使用TCP/IP协议）

WebSocket是HTML5中的协议，支持持久连接；而Http协议不支持持久连接。



## 13.进程与线程

进程间通信方式：

1. 管道：管道的传递数据是单向性的，只能从一方流向另一方，是一种半双工的通信方式；只用于有亲缘关系的进程间通信（父子进程）；管道他就像一个特殊的文件，但这个文件存在于内存之中，在创建管道时，系统为管道分配两个数据缓冲区，一个用来读数据，一个用来写数据，所以叫半双工。

2. 信号：在原理上，一个进程收到一个信号和收到一个中断请求差不多。信号是异步的，一个进程不必通过任何操作来等待信号的到来，事实上，进程也不知道信号到底什么时候到达。信号是进程间通信机制中唯一的一部通信机制。信号一般是使用信号处理器来进行的。

3. 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它通常作为一种锁机制，防止某进程正在访问共享资源时，其它进程也在访问该资源。因此主要作为进程间以及同一进程内不同线程之间的同步手段。主要使用P，V操作来实现的。

4. 消息队列：消息队列是一种比较高级的进程间通信方式，因为消息对垒是真的可以在进程间传送message，连传送一个“ I love you”都可以。消息队列是由消息组成的链表（有些书中也叫信箱），它可以被多个进程共享，可以供所有的进程在发送消息和接收消息时使用，并初始化一个无内容的消息。希望进入临界区的进程首先试图接收一条消息，若信箱为空，则阻塞该进程；一旦进程获得消息，它就执行其临界区然后把该消息放回信箱。注意一点：若有一条消息，则它仅仅能传递给一个进程，而其他进程被阻塞。若消息队列为空，则所有的进程被阻塞；一条消息可用时，仅仅激活一个阻塞进程并得到这一条消息。

5. 共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存可以说是最快的进程间通信方式。两个不同的进程A、B共享内存的意思是同一块物理内存被映射到A、B各自的进程地址空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只需要两次数据拷贝：一次是输入文件到共享内存中，另一次从共享内存区到输出文件。

   **注意**：管道、消息队列都是四次拷贝，分别是服务器端将信息从相应文件复制到 server 临时缓冲区，从临时缓冲区到 pipe 或 FIFO，客户端将信息从 FIFO 或 pipe 复制到 client 的临时缓冲区，再从临时缓冲区将信息写到输出文件。

6. 套接字：主要指TCP/IP这一块，与其他通信机制不同的是它可以用于不同设备间的通讯。

7. 有名管道：有名管道也是半双工的通信方式，允许无亲缘关系进程间的通信。

线程间通信方式：

锁机制：互斥锁，条件变量，自旋锁，读写自旋锁

1. 互斥锁：互斥锁和二元信号量原理基本上差不多。互斥是一个编程标志位，用来获取和释放一个对象。当需要的数据不能被分享或处理，进而在系统中的其他地方不能同时执行时，互斥被设置为锁定（一般为0），用于阻塞其它程序使用数据。当数据不再需要或程序运行结束时，互斥设定为非锁定。二元信号量和互斥量的区别在于，为互斥量加锁的进程和为互斥量解锁的进程必须是同一个进程。相比之下，二元信号量可能由某个进程执行加锁操作，但由另一个进程为其解锁。

2. 自旋锁：在Linux保护临界区的常用技术通常是自旋锁。在同一时刻，只有一个线程能获得自旋锁。其他任何试图获得自旋锁的线程将一直尝试（即自旋），直到获得了该锁。原理：自旋锁建立在内存中的一个整数上，任何线程进入临界区前都必须检查该值。若该值为0，则线程将该值设置为1，然后进入临界区。若该值非0，则该线程继续检查该值，直到它为0。

3. 读写自旋锁：读写自旋锁机制允许在内核中达到比基本自旋锁更高的并发程度。读写自旋锁允许多个线程同时以只读的方式访问同一数据结构。只有当一个进程想要更新数据结构时，才会互斥的访问改自旋锁。自旋锁在被读者拥有时，只要至少存在一个读者拥有该锁，写者就不能抢占该锁。而且，即使已有写者在等待改锁，新来的读者仍会抢先获得该自旋锁。

4. 条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

   ```c++
   //条件变量示例
   while (queue_empty(queue)) {
   	cond_wait(queue->nonempty, queue->mutex);  //释放锁，并休眠
   }
   ...
   cond_signal(queue->nonempty);	//唤醒
   ```

5. 信号量机制：信号量机制中的信号量包括信号量和二元信号量。
   信号量用于进程间和线程间的同步，它是一个整数值。在信号量上只可以进行三种操作，即初始化、递增、递减。这三种操作都是原子操作。递减用于阻塞一个进程，递增用于接触一个进程的阻塞。信号量也被称为计数信号量或者一般信号量。
   二元信号量：只取0值和1值的信号量。

6. 信号机制：信号是用于像一个进程或线程发生异步始键的机制。信号类似于硬件中断，没有优先级，即内核会公平的对待所有的信号量。对于同时发生的信号，一次只给进程一个信号，而没特定的次序。

   常用的信号有：

   1) SIGHUP 阻塞

   2) SIGINT 中断

   3) SIGQUIT 停止

   9) SIGKILL 杀死：终止进程

   15) SIGTERM 软件终止



## 14.线程切换和进程切换

进程切换需要分两步：切换页目录、刷新TLB以使用新的地址空间；切换内核栈和硬件上下文（寄存器）；而同一进程的线程间逻辑地址空间是一样的，不需要切换页目录、刷新TLB。